{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://mistral.ai/images/logo_hubc88c4ece131b91c7cb753f40e9e1cc5_2589_256x0_resize_q97_h2_lanczos_3.webp\" width=\"100\"/>\n",
    "<img src=\"https://cdn.iconscout.com/icon/free/png-256/free-python-3521655-2945099.png?f=webp&w=256\" width=\"35\"/>\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\">Génération d'un Dataset  pour proceder au fine-tuning d'un modèle Mistral.ai</h1>\n",
    "\n",
    "---\n",
    "<p style='text-align: justify;'>\n",
    "Ce notebook est un outil exploratoire de génération d'un dataset pour proceder au fine-tuning d'un modèle Mistral.ai. Il permet de générer un grand nombre de dialogue sur base d'un prompt. Ce prompt est construit sur base d'une question et d'une réponse. Le prompt est ensuite utilisé pour générer un grand nombre de dialogue. Ces dialogues sont ensuite stockés dans un fichier json. Ce fichier json est ensuite utilisé pour proceder au fine-tuning d'un modèle Mistral.ai.\n",
    "\n",
    "Dans cet exemple, nous allons générer un dataset pour un CV. La question est \"Comment je m'appelle\" et la réponse est \"Tu t'appelles [nom] [prénom]\". Le prompt est ensuite utilisé pour générer 50 variations de la question et de la réponse. Le but est de montrer la capacité du modèle à générer un dataset de qualité de dialogue sur base d'un prompt.\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## Installation et importation des données du CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ce morceaux de code permet de charger et de pouvoir naviguer dans les données disponibles dans le json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jean-Baptiste ASTRUZ'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Chemin vers le fichier JSON\n",
    "chemin_fichier = 'data.json'\n",
    "\n",
    "# Ouvrir et lire le fichier JSON\n",
    "with open(chemin_fichier, 'r') as fichier:\n",
    "    CV_data = json.load(fichier)\n",
    "\n",
    "question = \"Comment je m'appelle\"\n",
    "reponse = f\"Tu t'appelles {CV_data[0][\"Identite\"][\"Prenom\"] + \" \" + CV_data[0][\"Identite\"][\"Nom\"]}\"\n",
    "\n",
    "CV_data[0][\"Identite\"][\"Prenom\"] + \" \" + CV_data[0][\"Identite\"]['Nom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Création d'un prompt permettant de demander la génération d'un nombre arbitrairement grand de dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Ce prompt à pour but de générer un ordre dynamique qui puisse permettre de générer un grand nombre de réponse sur base d'un grand nombre de questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"je souhaite que tu me génères exactement 50 variations de la question {question}?. De plus, je souhaite que pour chaque variations, tu puisses donner la paraphrase de la réponse qui est \"{reponse}.\". N'hesites pas à reformuler la réponse\"\"\" + \"\"\"\n",
    "Génère la réponse sous forme de JSON uniquement avec la structure suivante:\n",
    "{\n",
    "\"messages\": [\n",
    "{\n",
    "\"role\": \"user\",\n",
    "\"content\" : \"Variation1 de la question\"\n",
    "},\n",
    "{\n",
    "\"role\" : \"assistant\",\n",
    "\"content\" : \"Variation1 de la réponse\"\n",
    "},\n",
    "{\n",
    "\"role\": \"user\",\n",
    "\"content\" : \"Variation2 de la question\"\n",
    "},\n",
    "{\n",
    "\"role\" : \"assistant\",\n",
    "\"content\" : \"Variation2 de la réponse\"\n",
    "},\n",
    "{\n",
    "\"role\": \"user\",\n",
    "\"content\" : \"Variation3 de la question\"\n",
    "},\n",
    "{\n",
    "\"role\" : \"assistant\",\n",
    "\"content\" : \"Variation3 de la réponse\"\n",
    "},\n",
    "...\n",
    "}\n",
    "Ne rajoute pas de texte en dehors de la structure JSON. ni avant ni après. Ne met pas de mise en forme markdown. De plus, tu génères EXACTEMENT 50 variations. Tu ne parles qu'en français.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Installation et importation des packages nécessaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "On récupère les bons packages pour pouvoir faire le travail d'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient # Import the MistralClient from the mistralai.client module\n",
    "from mistralai.models.chat_completion import ChatMessage # Import the ChatMessage from the mistralai.models.chat_completion module\n",
    "from dotenv import load_dotenv # Import the load_dotenv function from the dotenv module\n",
    "import os # Import the os module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Définition du client Mistral.ai et du modèle à utiliser\n",
    "On défini le client et le modèle d'IA que l'on va utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model = \"open-codestral-mamba\"\n",
    "api_key= os.getenv('MISTRAL_API_KEY')\n",
    "client = MistralClient(api_key=api_key, timeout=180)\n",
    "responses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "On execute le prompt pour pouvoir récupérer les exemples de diaolgue fournis en JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=prompt)\n",
    "]\n",
    "responses.append(client.chat(model=model, messages=messages, response_format={\"type\": \"json_object\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Enregistrement des résultats\n",
    "On va simplement enregistrer les résultats pour pouvoir les charger plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier JSON a été sauvegardé avec succès dans le fichier Comment_je_m'appelle.json.\n"
     ]
    }
   ],
   "source": [
    "json_text = responses[0].choices[0].message.content\n",
    "\n",
    "json_object = json.loads(json_text)\n",
    "\n",
    "# Enregistrer les données JSON dans un fichier\n",
    "with open(f'{question.replace(\" \", \"_\")}.json', 'w') as json_file:\n",
    "    json.dump(json_object, json_file, indent=4)\n",
    "\n",
    "print(f\"Le fichier JSON a été sauvegardé avec succès dans le fichier {question.replace(\" \", \"_\")}.json.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification du nombre de messages générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le rôle 'user' apparaît 42 fois.\n",
      "Le rôle 'assistant' apparaît 42 fois.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Charger les données JSON depuis le fichier\n",
    "with open(f'{question.replace(\" \", \"_\")}.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker le nombre d'occurrences de chaque rôle\n",
    "role_count = {}\n",
    "\n",
    "# Parcourir la liste de messages\n",
    "for message in data['messages']:\n",
    "    role = message['role']\n",
    "    # Si le rôle est déjà dans le dictionnaire, incrémenter le compteur\n",
    "    if role in role_count:\n",
    "        role_count[role] += 1\n",
    "    # Sinon, ajouter le rôle au dictionnaire avec un compteur initial de 1\n",
    "    else:\n",
    "        role_count[role] = 1\n",
    "\n",
    "# Afficher le nombre d'occurrences de chaque rôle\n",
    "for role, count in role_count.items():\n",
    "    print(f\"Le rôle '{role}' apparaît {count} fois.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
